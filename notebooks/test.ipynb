{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 로드 및 실행 노트북"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"main func for training\"\"\"\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import pprint\n",
    "import datetime\n",
    "\n",
    "import ujson\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0511 14:42:47.740202 139623672854272 file_utils.py:41] PyTorch version 1.4.0 available.\n"
     ]
    }
   ],
   "source": [
    "import config as cfg\n",
    "\n",
    "import model as m\n",
    "import utils\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## config\n",
    "- INPUT_BASE는 dev42.csv 를 가지고 있음\n",
    "    - dev42.csv는 mkdev.py를 통해 생성된 파일이며, 다 귀찮고 결과 파일이 필요할 경우 그에게 문의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('roberta', 160)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.MODEL_TYPE, cfg.MAX_SEQ_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train42.csv',\n",
       " 'test.csv',\n",
       " 'train_folds.csv.zip',\n",
       " 'tweet-sentiment-extraction.zip',\n",
       " 'dev42.csv',\n",
       " 'train_folds.csv',\n",
       " 'train.csv',\n",
       " 'train_folds_v2_num2zero.csv',\n",
       " 'sample_submission.csv',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(cfg.INPUT_BASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global params\n",
    "- MODEL_PATH ; 학습 weight 경로 (model_x.pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_ID = 0\n",
    "MODEL_PATH = '/DATA/image-search/kgg/best/normal_29105s_160t_16b_3e-5lr_roberta'\n",
    "\n",
    "VERBOSE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset-metadata.json',\n",
       " 'model_1.pt',\n",
       " 'config.py',\n",
       " 'res_29105_roberta_score_0.7123.json',\n",
       " 'model_4.pt',\n",
       " 'model_2.pt',\n",
       " 'model_3.pt',\n",
       " 'model_0.pt']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:{}'.format(GPU_ID))\n",
    "    print(torch.cuda.device_count())\n",
    "    print(torch.cuda.get_device_name(GPU_ID))\n",
    "else:\n",
    "    print('no gpus available')\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "- 폴더명에서 메타정보 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['//DATA/image-search/kgg/best/normal_29105s_160t_16b_3e-5lr_roberta']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len = int(MODEL_PATH.split('t_')[-2].split('_')[-1])\n",
    "\n",
    "model_path = MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV ->  res_29105_roberta_score_0.7123.json\n"
     ]
    }
   ],
   "source": [
    "finished = sum([1 for path in os.listdir(model_path) if 'res' in path]) > 0\n",
    "if not finished:\n",
    "    print('not finished yet', model_path)\n",
    "\n",
    "if finished:\n",
    "    for path in os.listdir(model_path):\n",
    "        if 'res' in path:\n",
    "            print('CV -> ', path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 로드 (K-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0511 14:59:10.858190 139623672854272 configuration_utils.py:284] loading configuration file ./roberta/roberta-base-config.json\n",
      "I0511 14:59:10.859737 139623672854272 configuration_utils.py:322] Model config RobertaConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265,\n",
      "  \"xla_device\": null\n",
      "}\n",
      "\n",
      "I0511 14:59:10.860753 139623672854272 modeling_utils.py:517] loading weights file ./roberta/roberta-base-pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cur model path: //DATA/image-search/kgg/best/normal_29105s_160t_16b_3e-5lr_roberta\n",
      "normal model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0511 14:59:16.418360 139623672854272 configuration_utils.py:284] loading configuration file ./roberta/roberta-base-config.json\n",
      "I0511 14:59:16.419954 139623672854272 configuration_utils.py:322] Model config RobertaConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265,\n",
      "  \"xla_device\": null\n",
      "}\n",
      "\n",
      "I0511 14:59:16.420804 139623672854272 modeling_utils.py:517] loading weights file ./roberta/roberta-base-pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0511 14:59:21.848900 139623672854272 configuration_utils.py:284] loading configuration file ./roberta/roberta-base-config.json\n",
      "I0511 14:59:21.850666 139623672854272 configuration_utils.py:322] Model config RobertaConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265,\n",
      "  \"xla_device\": null\n",
      "}\n",
      "\n",
      "I0511 14:59:21.851621 139623672854272 modeling_utils.py:517] loading weights file ./roberta/roberta-base-pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0511 14:59:27.681416 139623672854272 configuration_utils.py:284] loading configuration file ./roberta/roberta-base-config.json\n",
      "I0511 14:59:27.683131 139623672854272 configuration_utils.py:322] Model config RobertaConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265,\n",
      "  \"xla_device\": null\n",
      "}\n",
      "\n",
      "I0511 14:59:27.683959 139623672854272 modeling_utils.py:517] loading weights file ./roberta/roberta-base-pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0511 14:59:33.436320 139623672854272 configuration_utils.py:284] loading configuration file ./roberta/roberta-base-config.json\n",
      "I0511 14:59:33.438283 139623672854272 configuration_utils.py:322] Model config RobertaConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265,\n",
      "  \"xla_device\": null\n",
      "}\n",
      "\n",
      "I0511 14:59:33.439496 139623672854272 modeling_utils.py:517] loading weights file ./roberta/roberta-base-pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal model\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "print('Cur model path:', model_path)\n",
    "\n",
    "root = cfg.INPUT_BASE\n",
    "test_data = pd.read_csv('{}dev42.csv'.format(root))\n",
    "\n",
    "test_data['text'] = test_data.apply(lambda row: str(row.text).strip(), axis=1)\n",
    "\n",
    "electra = cfg.MODEL_STR[cfg.ELECTRA]\n",
    "roberta = cfg.MODEL_STR[cfg.ROBERTA]\n",
    "if electra in model_path:\n",
    "    model_type = electra\n",
    "elif roberta in model_path:\n",
    "    model_type = roberta\n",
    "\n",
    "for i in range(cfg.K_FOLD):\n",
    "    if 'normal' in model_path:\n",
    "        print('normal model')\n",
    "        _model = m.SentimentExtractor(model=model_type, device=device)\n",
    "    elif 'cnn' in model_path:\n",
    "        print('cnn model')\n",
    "        _model = m.SentimentExtractorCNN(model=model_type, device=device)\n",
    "    _model.to(device)\n",
    "    _model.load_state_dict(torch.load(f'{model_path}/model_{i}.pt'))\n",
    "    _model.eval()\n",
    "    models.append(_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 토크나이저 사용전 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.init_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dataset.TweetDataset(\n",
    "    tweet=test_data.text.values,\n",
    "    sentiment=test_data.sentiment.values,\n",
    "    selected_text=test_data.selected_text.values,\n",
    "    tokenizer=m.tokenizer,\n",
    "    max_seq_len=max_seq_len,\n",
    "    model_type=model_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev셋에 대한 스코어 구하기!\n",
    "- VERBOSE True일 경우, 1.0 점 미만인 경우 출력\n",
    "- 후처리 로직은 아래 로직에 추가하여, 스코어 상승 여부 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "\n",
      "3d9d4b0b55 (negative, 0.2222222222222222)\n",
      " i donbt like to peel prawns, i also dont like going shopping, running out of money and crawling round the car looking for more\n",
      "Answ:  dont like go\n",
      "Pred:  i donbt like to peel prawns, i also dont like\n",
      "\n",
      "bffa3ddd61 (negative, 0.5)\n",
      " i miss you bby wish you were going tomorrow to make me do good.\n",
      "Answ:  i miss you bby\n",
      "Pred:  i miss\n",
      "\n",
      "401869d615 (negative, 0.0)\n",
      " graduation is done im a little sad.. anyone want to hang out???\n",
      "Answ:  sad.\n",
      "Pred:  sad..\n",
      "\n",
      "5f93cc70ff (negative, 0.2222222222222222)\n",
      " Bugger. forgot I still have washing in my machine\n",
      "Answ:  Bugger. forgot I still have washing in my machine\n",
      "Pred:  Bugger. forgot\n",
      "\n",
      "e4e9b8713a (negative, 0.2)\n",
      " My back hurts...really bad\n",
      "Answ:  .really bad\n",
      "Pred:  My back hurts...really bad\n",
      "\n",
      "9d3a1e0269 (negative, 0.25)\n",
      " really hopes her car`s illness is not terminal...\n",
      "Answ:  illness\n",
      "Pred:  illness is not terminal...\n",
      "\n",
      "a0a306868a (negative, 0.0)\n",
      " lost my tooth 2day whilst i was eating gum...oww\n",
      "Answ:  oww\n",
      "Pred:  lost\n",
      "\n",
      "9a6f4d05d5 (positive, 0.0)\n",
      " 35mins through the 1hr 20mins Google Wave demo, that looks a lot of fun, would love to test it though. http://bit.ly/WnMSc\n",
      "Answ:  would love to test it though.\n",
      "Pred:  that looks a lot of fun,\n",
      "\n",
      "7b69f49c42 (positive, 0.375)\n",
      " tonight in party w/ my girls (minus vita)\n",
      "Answ:  tonight in party w/ my girls (minus vita)\n",
      "Pred:  tonight in party\n",
      "\n",
      "294df18b9f (positive, 0.3333333333333333)\n",
      " I saw the play of it here, it was amazing\n",
      "Answ:  amazing\n",
      "Pred:  it was amazing\n",
      "\n",
      "e5160216a5 (negative, 0.8333333333333334)\n",
      " ohh my tooth is hurts ohh im sad it very hurts\n",
      "Answ:  im sad it very hurts\n",
      "Pred:  hurts ohh im sad it very hurts\n",
      "\n",
      "51f4502988 (negative, 0.5)\n",
      " My dog is officially depressed that my brother`s dogs are gone. He doesn`t want to go outside and when we did, he play half-heartedly.\n",
      "Answ:  officially depressed\n",
      "Pred:  depressed\n",
      "\n",
      "a97db072ed (positive, 0.0)\n",
      " Gonna celebrate Mothers Day with the family but gonna start the partying tonite\n",
      "Answ:  partying\n",
      "Pred:  celebrate\n",
      "\n",
      "9191e574bb (negative, 0.0)\n",
      " I just stuck my finger down my throat and there are a bunch of bumps on my tongue & throat.\n",
      "Answ:  stuck\n",
      "Pred:  bumps\n",
      "\n",
      "45b0430eb9 (positive, 0.25)\n",
      " http://twitpic.com/4wukt - We bought Ludi her own rug. Dogs are the best\n",
      "Answ:  best\n",
      "Pred:  Dogs are the best\n",
      "\n",
      "754ebd84b4 (negative, 0.5)\n",
      " http://twitpic.com/67qv3 - Me at Forever 21 Ethan couldn`t be there\n",
      "Answ:  Me at Forever 21 Ethan couldn`t be there\n",
      "Pred:  Ethan couldn`t be there\n",
      "\n",
      "18f60b8879 (negative, 0.0)\n",
      " but my bday is JUNE 19.. this is wack... and ihavent seen any promotions for my bday party someone better finagle this asap!\n",
      "Answ:  wack.\n",
      "Pred:  this is wack...\n",
      "\n",
      "954ab76021 (positive, 0.5)\n",
      " Feeling loved! My Mom got me a Nikon Cool Pix for my birthday!!!!\n",
      "Answ:  loved!\n",
      "Pred:  Feeling loved!\n",
      "\n",
      "443d30a0ba (negative, 0.07142857142857142)\n",
      " _rc234 haha yup. but still have a terrible headache and super swollen and puffy eyes! i dont think im going out today.ugh!\n",
      "Answ:  terrible headache and super swollen and puffy eyes! i dont think im going out today.ugh!\n",
      "Pred:  terrible\n",
      "\n",
      "35e2ce08fc (positive, 0.5)\n",
      " And the Sun is shinning.........at last\n",
      "Answ:  Sun is shinning.........at last\n",
      "Pred:  shinning.........at last\n",
      "\n",
      "ae8fd767fc (negative, 0.25)\n",
      " I`m sleepy but is feeling under the weather! ugh! These **** tonsils. I need some company or somebody to talk too!\n",
      "Answ:  ugh! These **** tonsils.\n",
      "Pred:  ugh!\n",
      "\n",
      "2209fb4785 (negative, 0.6666666666666666)\n",
      " That was stone cold Crazy.... ?\n",
      "Answ:  That was stone cold Crazy.\n",
      "Pred:  That was stone cold Crazy....\n",
      "\n",
      "77711764bf (positive, 0.0)\n",
      " Good Morning! - Court - Crossfit - Bible Study - Someone very special`s house http://tinyurl.com/cjs668\n",
      "Answ:  very special`s\n",
      "Pred:  Good Morning!\n",
      "\n",
      "fc92519d0d (negative, 0.5)\n",
      " Dang... that IS disappointing\n",
      "Answ:  IS disappointing\n",
      "Pred:  disappointing\n",
      "\n",
      "b31f326e68 (positive, 0.07142857142857142)\n",
      " How much longer is the NKOTB Block Party? Love it! I need to go to bed so just wondering what time it`s over..LOL..thanks!\n",
      "Answ:  Love\n",
      "Pred:  Love it! I need to go to bed so just wondering what time it`s over..LOL..thanks!\n",
      "\n",
      "0bc2e46e4e (negative, 0.8571428571428571)\n",
      " Thanks! My mom`s seed is larger and already cracked (and planted). I hope Avalina isn`t a dud!\n",
      "Answ:  . I hope Avalina isn`t a dud!\n",
      "Pred:  I hope Avalina isn`t a dud!\n",
      "\n",
      "c0f58575bf (negative, 0.5)\n",
      " i want to experience snow we don`t have snow here and it sucks\n",
      "Answ:  t sucks\n",
      "Pred:  sucks\n",
      "\n",
      "cb60620a4f (positive, 0.05555555555555555)\n",
      " Goodmorning twitter, oh my gosh, i woke up soooo nice, lol ... oh hai thar twitterverse. Happy #mothersday everybody (especially mine)\n",
      "Answ:  Goodmorning twitter, oh my gosh, i woke up soooo nice, lol ... oh hai thar twitterverse. Happy #mothersday everybody\n",
      "Pred:  Happy\n",
      "\n",
      "f00bd4ea4e (positive, 0.5)\n",
      " aww thanx andy\n",
      "Answ:  thanx\n",
      "Pred:  aww thanx\n",
      "\n",
      "252e56c4d1 (negative, 0.3333333333333333)\n",
      " So tired & ready for bed!! Really in the mood for salt & pepper chicken wings & noodles but have no money on me for a Chinese!\n",
      "Answ:  So tired &\n",
      "Pred:  tired\n",
      "\n",
      "43b0426667 (negative, 0.3333333333333333)\n",
      " lol, i`ve done that one b4 i`m a victim 2 that! lol\n",
      "Answ:  i`m a victim\n",
      "Pred:  victim\n",
      "\n",
      "e9785cbd8c (negative, 0.0)\n",
      " i would slip and fall... on the dirty school bathroom floor. fml.\n",
      "Answ:  i would slip and fall..\n",
      "Pred:  dirty\n",
      "\n",
      "77338f26c5 (positive, 0.16666666666666666)\n",
      " i jus love doin night shifts...will be done in an hour\n",
      "Answ:  i jus love doin night shifts...\n",
      "Pred:  love\n",
      "\n",
      "ce5dd24a33 (negative, 0.6)\n",
      " I have to reupload the **** thing again\n",
      "Answ:  reupload the **** thing again\n",
      "Pred:  **** thing again\n",
      "\n",
      "3c3ff93959 (positive, 0.14285714285714285)\n",
      " Invisible car helps to boost recycling. Honest http://twurl.nl/fdgmyo\n",
      "Answ:  Invisible car helps to boost recycling. Honest\n",
      "Pred:  helps\n",
      "\n",
      "b38290dfd8 (negative, 0.75)\n",
      " You did know, you just couldn`t remember!!\n",
      "Answ:  just couldn`t remember!!\n",
      "Pred:  you just couldn`t remember!!\n",
      "\n",
      "8a2a4790e0 (negative, 0.14285714285714285)\n",
      " Work in that heat is horrible !\n",
      "Answ:  Work in that heat is horrible !\n",
      "Pred:  horrible\n",
      "\n",
      "4287a0fce7 (positive, 0.0)\n",
      " hahaha, I was busy, now I see what I replied to you! Yes that is true\n",
      "Answ:  hahaha, I was busy, now I see what I replied to you!\n",
      "Pred:  Yes that is true\n",
      "\n",
      "7048b3a9c0 (positive, 0.5)\n",
      " Nako! Umuulan pa naman! Anyway, enjoy the bike rides!\n",
      "Answ:  , enjoy\n",
      "Pred:  enjoy\n",
      "\n",
      "3e9559f5a8 (positive, 0.2)\n",
      " tonight was hilariouss i loveeee everyone that was theree\n",
      "Answ:  loveeee\n",
      "Pred:  tonight was hilariouss i loveeee\n",
      "[100]\n",
      "\n",
      "82395294cf (positive, 0.25)\n",
      " goooodnight everyone! and Happy Mothers Day to all the mothers out there.\n",
      "Answ:  Happy\n",
      "Pred:  goooodnight everyone! and Happy\n",
      "\n",
      "875d366982 (positive, 0.3333333333333333)\n",
      " Enjoy the coffee. We miss you, petite puce (adica Puricel in franceza)\n",
      "Answ:  Enjoy the coffee.\n",
      "Pred:  Enjoy\n",
      "\n",
      "771b845b38 (negative, 0.5)\n",
      " ahhh fusterated\n",
      "Answ:  fusterated\n",
      "Pred:  ahhh fusterated\n",
      "\n",
      "27024dbb18 (positive, 0.0)\n",
      " The sun is shining brightly and the day has just begun! What`s in store? Wandering around les calanques maybe? Vin, definitely!\n",
      "Answ:  definitely!\n",
      "Pred:  The sun is shining brightly\n",
      "\n",
      "17fc6384ed (negative, 0.3333333333333333)\n",
      " Miss Cauzinhoooo already\n",
      "Answ:  Miss Cauzinhoooo already\n",
      "Pred:  Miss\n",
      "\n",
      "2ab82634d5 (positive, 0.25)\n",
      " had an awsome salad! I recommend getting the Spicey buffalo chicken salad!\n",
      "Answ:  had an awsome salad!\n",
      "Pred:  awsome\n",
      "\n",
      "adac9ee2e1 (positive, 0.3333333333333333)\n",
      " I just started watching 30 Rock too, borrowed seasons 1 and 2 from my dad so good.\n",
      "Answ:  so goo\n",
      "Pred:  so good.\n",
      "\n",
      "3b3d48063c (negative, 0.23529411764705882)\n",
      " it was a biligual sweatshop LOL I talk 2 him once in a while but not as much, he got an r6\n",
      "Answ:  but not as much,\n",
      "Pred:  it was a biligual sweatshop LOL I talk 2 him once in a while but not as much,\n",
      "\n",
      "b519ba7eaf (positive, 0.0)\n",
      " Heavens, not good I can empathise. Fingers crossed it doesn`t come to anything and you can sleep easy. Wishing for the best...\n",
      "Answ:  Heavens,\n",
      "Pred:  Wishing for the best...\n",
      "\n",
      "c00e8432c2 (positive, 0.25)\n",
      " happy star wars dayyyy =D and hbd to uncle LEE\n",
      "Answ:  happy star wars dayyyy\n",
      "Pred:  happy\n",
      "\n",
      "197e8317da (negative, 0.5)\n",
      " Actual wiki entry 'The Million Dollar Homepage' made me just shake my head due to the fact that ... sometimes...somtimes things just work\n",
      "Answ:  made me just shake my head\n",
      "Pred:  shake my head\n",
      "\n",
      "672b861395 (negative, 0.06666666666666667)\n",
      " Slept at my parents the bed was hard as a rock now my back feels like a rock\n",
      "Answ:  Slept at my parents the bed was hard as a rock now my back feels like a rock\n",
      "Pred:  hard\n",
      "\n",
      "acbc90fc39 (positive, 0.5)\n",
      " YAY to som1 i no on twitter...slowly slowly rest of the grade will come around...hah i hope ur ready for my constant tweets!!\n",
      "Answ:  i hope\n",
      "Pred:  hope\n",
      "\n",
      "699c07b35c (negative, 0.0)\n",
      " ****. it should be recoverable. it`s just the boot part that`s messed up. grr argh. my business was on there.\n",
      "Answ:  . it should be recoverable.\n",
      "Pred:  ****.\n",
      "\n",
      "3f96c39a12 (negative, 0.5)\n",
      " http://www.bodybuilding.com/fun/richardchan.htm OMFG this dude looks well `ard! He puts me to shame...\n",
      "Answ:  this dude looks well `ard! He puts me to shame...\n",
      "Pred:  He puts me to shame...\n",
      "\n",
      "e69012514b (negative, 0.2)\n",
      " I miss rollerblading down Shoreline.\n",
      "Answ:  I miss rollerblading down Shoreline.\n",
      "Pred:  miss\n",
      "\n",
      "df0d78273e (negative, 0.3333333333333333)\n",
      " Never ever smoking around you again.\n",
      "Answ:  Never ever\n",
      "Pred:  Never ever smoking around you again.\n",
      "\n",
      "024535ea03 (negative, 0.5)\n",
      " btw ian watkins has stopped following me so i am a wee bit pissed off!\n",
      "Answ:  pissed\n",
      "Pred:  pissed off!\n",
      "\n",
      "bac324b47f (negative, 0.75)\n",
      " oh ... you`ve been superseeded? not good enough\n",
      "Answ:  ? not good enough\n",
      "Pred:  not good enough\n",
      "\n",
      "65b8688268 (positive, 0.0)\n",
      " I`m thinking the 'Chevrolet Doom' would be fitting for GM\n",
      "Answ:  thinking\n",
      "Pred:  fitting\n",
      "\n",
      "04068059fa (negative, 0.3333333333333333)\n",
      " : aww im sorry honey. that stinks\n",
      "Answ:  sorry\n",
      "Pred:  aww im sorry\n",
      "\n",
      "5ad2a2d630 (positive, 0.8571428571428571)\n",
      " but I don`t want to hurt you\n",
      "Answ:  I don`t want to hurt you\n",
      "Pred:  but I don`t want to hurt you\n",
      "\n",
      "2c60434fea (negative, 0.5)\n",
      " RE: Hulu Desktop in Windows 7 Media Center http://bit.ly/DEc64but not on extenders unfortunately\n",
      "Answ:  s unfortunately\n",
      "Pred:  unfortunately\n",
      "\n",
      "7a1ba01fa0 (positive, 0.5)\n",
      " Good morning It`s raining here.\n",
      "Answ:  Good morning\n",
      "Pred:  Good\n",
      "\n",
      "cb4902da0a (positive, 0.0)\n",
      " yeah the tomato paste and oil is traditional on a sandwich.. eat it with some olives and maltese cheese yum!\n",
      "Answ:  yum\n",
      "Pred:  yum!\n",
      "\n",
      "718fa1b02e (negative, 0.08333333333333333)\n",
      " is there something wrong with the internet in chelmsford? my tv on demad isnt working right and my internet is SUPER slow\n",
      "Answ:  my tv on demad isnt working right and my internet is SUPER slow\n",
      "Pred:  slow\n",
      "\n",
      "95828aebf3 (negative, 0.16666666666666666)\n",
      " Missing nathan and the bccg already. And my best friends that tried to visit me Heading back tomorrow afternoon.\n",
      "Answ:  Missing nathan and the bccg already.\n",
      "Pred:  Missing\n",
      "\n",
      "b65c7688ce (positive, 0.2)\n",
      " thursday night was amazing taylor swift gave me one of her braclets\n",
      "Answ:  thursday night was amazing ta\n",
      "Pred:  amazing\n",
      "\n",
      "aa20ff7392 (negative, 0.5714285714285714)\n",
      " I wasn`t given an exact date, but it shouldn`t be much longer. Please accept our apologies for the inconvenience!\n",
      "Answ:  Please accept our apologies for the inconvenience!\n",
      "Pred:  apologies for the inconvenience!\n",
      "\n",
      "c3b00da593 (negative, 0.09090909090909091)\n",
      " oops just unfollowed everyone! anywayz, will build my Twitter Empire.... again....\n",
      "Answ:  oops just unfollowed everyone! anywayz, will build my Twitter Empire.... again....\n",
      "Pred:  oops\n",
      "\n",
      "880efa1bec (positive, 0.5)\n",
      " I listen it right now - so much fun!!! No I just have to get it somehow\n",
      "Answ:  so much fun!!\n",
      "Pred:  so much fun!!!\n",
      "\n",
      "59a28d3596 (positive, 0.8823529411764706)\n",
      " Sorry for your loss. I know how you feel. She or he was a lucky cat.\n",
      "Answ:  Sorry for your loss. I know how you feel. She or he was a lucky cat\n",
      "Pred:  Sorry for your loss. I know how you feel. She or he was a lucky cat.\n",
      "\n",
      "87580d31b9 (positive, 0.2)\n",
      " is getting her hair did shortly! and hoping everything is going well for her friend currently getting surgery!\n",
      "Answ:  hoping everything is going well\n",
      "Pred:  hoping\n",
      "\n",
      "4246aba5de (positive, 0.125)\n",
      " morrrning. time for school. (: time to learn!\n",
      "Answ:  morrrning. time for school. (: ti\n",
      "Pred:  time to learn!\n",
      "\n",
      "3a8a7232eb (negative, 0.25)\n",
      " bed. with stomach ache\n",
      "Answ:  bed. with stomach ache\n",
      "Pred:  ache\n",
      "\n",
      "22eef0949d (negative, 0.6666666666666666)\n",
      " Gettin some fuel, too bad no one is reading this!\n",
      "Answ:  too bad no\n",
      "Pred:  too bad\n",
      "\n",
      "6584036615 (negative, 0.0)\n",
      " Why are the sinks in hospital toilets so low? Now the **** of my grey suit is spattered with water! Just in time for Physio\n",
      "Answ:  so low? No\n",
      "Pred:  spattered with water!\n",
      "\n",
      "85bd4a3db0 (positive, 0.3333333333333333)\n",
      " i dont even have a WII! b likes xbox, so that`s what we have do you use it?\n",
      "Answ:  b likes xbox,\n",
      "Pred:  likes\n",
      "\n",
      "12c89d051d (negative, 0.3333333333333333)\n",
      " That was ****.\n",
      "Answ:  ****.\n",
      "Pred:  That was ****.\n",
      "\n",
      "99fb8ae709 (positive, 0.16666666666666666)\n",
      " My windows open and its not that cold ahahah\n",
      "Answ:  d its not that cold ahahah\n",
      "Pred:  ahahah\n",
      "[200]\n",
      "\n",
      "7aeef04698 (positive, 0.3333333333333333)\n",
      " My favourite photo (that I took) from last night: http://tinyurl.com/oto5sz can`t wait to see `s pics\n",
      "Answ:  favourite photo (t\n",
      "Pred:  favourite\n",
      "\n",
      "0ff3a55c45 (positive, 0.3333333333333333)\n",
      " Just got back from `s party! Sooo much fun! Boom boom pow~ hahaha! ooh and I just told my mom happy mother`s day\n",
      "Answ:  fun!\n",
      "Pred:  Sooo much fun!\n",
      "\n",
      "0034cbc1c3 (positive, 0.047619047619047616)\n",
      " mmmm it all sounds tasty. i had some spiced rum earlier, yummmmmyyyy also herbs are always good although better when shared\n",
      "Answ:  mmmm it all sounds tasty. i had some spiced rum earlier, yummmmmyyyy also herbs are always good although better when shared\n",
      "Pred:  tasty.\n",
      "\n",
      "92a3fdbf42 (positive, 0.2)\n",
      " o sweet i saw him last year with kenny & sugarland will be with kenny this year.. i have seen them b4... love them.. gknight\n",
      "Answ:  . love them\n",
      "Pred:  love them.. gknight\n",
      "\n",
      "6b78e2821a (negative, 0.2)\n",
      " would like june the nineteenth to hurry it self up, as she is waiting very impatiently to see wes carr\n",
      "Answ:  she is waiting very impatiently\n",
      "Pred:  impatiently\n",
      "\n",
      "469917b711 (positive, 0.5)\n",
      " nice capture\n",
      "Answ:  nice capture\n",
      "Pred:  nice\n",
      "\n",
      "f5d996191d (positive, 0.1111111111111111)\n",
      " Thank you so much. That was so nice of you and I was happy to hear you voice You`ve really started something Good!! xo\n",
      "Answ:  d I was happy to hear you voice You`ve really started something Good!\n",
      "Pred:  Thank you so much. That was so nice\n",
      "\n",
      "5156e1f9c9 (negative, 0.07142857142857142)\n",
      " I agree with _Crazy it`s not worth it - block them & let Twitter police know about harrassment.\n",
      "Answ:  harrassment.\n",
      "Pred:  it`s not worth it - block them & let Twitter police know about harrassment.\n",
      "\n",
      "6b13a4751a (positive, 0.0)\n",
      " you always seem to know exactly the right thing to say. thanks. - http://ilikeucoz.com/m/1123 #youregreat\n",
      "Answ:  #youregreat\n",
      "Pred:  thanks.\n",
      "\n",
      "e28b4c4fb7 (negative, 0.1111111111111111)\n",
      " my three most hated words are 'see you monday'\n",
      "Answ:  my three most hated words are 'see you monday'\n",
      "Pred:  hated\n",
      "\n",
      "09256ab5f3 (negative, 0.6666666666666666)\n",
      " i know my mom is going up there monday with me to get it changed. i`m so upset\n",
      "Answ:  so upset\n",
      "Pred:  i`m so upset\n",
      "\n",
      "53f12f16ca (positive, 0.6666666666666666)\n",
      " very cute kitty\n",
      "Answ:  very cute kitty\n",
      "Pred:  very cute\n",
      "\n",
      "979d46a2d4 (negative, 0.125)\n",
      " again your fault i didnt make u leave\n",
      "Answ:  again your fault i didnt make u leave\n",
      "Pred:  fault\n",
      "\n",
      "b092dea94f (negative, 0.08333333333333333)\n",
      " That is annoying. What gear is it? I`ll take it off your hands\n",
      "Answ:  That is annoying. What gear is it? I`ll take it off your hands\n",
      "Pred:  annoying.\n",
      "\n",
      "13d1cd323a (negative, 0.0)\n",
      " my back hurts have a heating pad on it... stupid ladder y did you have to collapse and make me fall on my back/bum???\n",
      "Answ:  stupid ladder y did you have to collapse and make me fall on my back/bum???\n",
      "Pred:  hurts\n",
      "\n",
      "086ea05de7 (positive, 0.0)\n",
      " thanks for the ok ...hope we can tweet more down the road\n",
      "Answ:  .hope\n",
      "Pred:  thanks\n",
      "\n",
      "ca8f9abdbd (positive, 0.07692307692307693)\n",
      " thanks and ill cross my fingers for you, that the rain will stop\n",
      "Answ:  thanks and ill cross my fingers for you, that the rain will stop\n",
      "Pred:  thanks\n",
      "\n",
      "9b2f24abcf (positive, 0.0)\n",
      " wants her boo btw love fhnixon`s posts hilarious!!!!\n",
      "Answ:  hilarious!\n",
      "Pred:  love fhnixon`s posts hilarious!!!!\n",
      "\n",
      "0b6a76270b (negative, 0.5)\n",
      " oh and #antiboyle didn`t work out either never too much of a bad thing eh uk eh\n",
      "Answ:  bad\n",
      "Pred:  bad thing\n",
      "\n",
      "f804ea3526 (positive, 0.0)\n",
      " No but I just checked and got it LOL. You are ok! I went live for a few minutes and everything is fine.\n",
      "Answ:  t LOL. You are ok!\n",
      "Pred:  everything is fine.\n",
      "\n",
      "6442cd9e0b (positive, 0.5)\n",
      " Beer pong and dubstep. Good nite\n",
      "Answ:  Good nite\n",
      "Pred:  Good\n",
      "\n",
      "840e89f387 (positive, 0.5)\n",
      " _henrie Can you do a shoutout to holland please ? You got a lot of fans here!\n",
      "Answ:  lot of fans\n",
      "Pred:  You got a lot of fans\n",
      "\n",
      "c58cd47886 (negative, 0.0)\n",
      " Not feelin right. Hope the feeling passes. Stupid stomach.\n",
      "Answ:  Not feelin right.\n",
      "Pred:  Stupid\n",
      "\n",
      "29ffd15818 (negative, 0.4)\n",
      " she`s in LA, wanting sun today... but apparently LA isn`t cooperating\n",
      "Answ:  A isn`t cooperating\n",
      "Pred:  apparently LA isn`t cooperating\n",
      "\n",
      "e4ca3bccbc (negative, 0.11538461538461539)\n",
      " Cant believe Venus lost. A real shame. Smh. I think im getting sick Had such a **** week, doesnt look like the wknd is gona be better!\n",
      "Answ:  Cant believe Venus lost. A real shame. Smh. I think im getting sick Had such a **** week, doesnt look like the wknd is gona be better!\n",
      "Pred:  A real shame.\n",
      "\n",
      "61c3b437d9 (positive, 0.5)\n",
      " feeling like in 16 again - watching TWILIGHT & enjoying it\n",
      "Answ:  enjoying\n",
      "Pred:  enjoying it\n",
      "\n",
      "a0a8bb5ad1 (positive, 0.75)\n",
      " are you kidding me?! that looks incredible!!! Lay out and swim a lot for me, stuck in the cold NYC\n",
      "Answ:  ! that looks incredible!!!\n",
      "Pred:  that looks incredible!!!\n",
      "\n",
      "b81ccfae03 (positive, 0.6666666666666666)\n",
      " diggin` your moustachio! Looking good daddio!\n",
      "Answ:  Looking good daddio!\n",
      "Pred:  Looking good\n",
      "\n",
      "89d58a0517 (positive, 0.4)\n",
      " Good luck whit the show tonite man, ill be watching\n",
      "Answ:  Good luck whit the show\n",
      "Pred:  Good luck\n",
      "\n",
      "74fa55b2ad (negative, 0.5)\n",
      " I feel bad over everything.. How can I be so stupid? Why was I so harsh? Its my fault, I know it. I`m sorry SaVvy, love you guys<3\n",
      "Answ:  feel bad ov\n",
      "Pred:  I feel bad\n",
      "\n",
      "385e0fb48e (negative, 0.5)\n",
      " wearing a pair of trousers that were loose last year, tight this year\n",
      "Answ:  tight this year\n",
      "Pred:  loose last year, tight this year\n",
      "\n",
      "fb58fcae23 (negative, 0.2)\n",
      " I`m soo jealous right now!!\n",
      "Answ:  I`m soo jealous right now!!\n",
      "Pred:  jealous\n",
      "\n",
      "97e811cd65 (negative, 0.16666666666666666)\n",
      " missing my bffls! missing my friday night dates! hot dogs for dinner then who knows what the evening holds!\n",
      "Answ:  missing my bffls! missing my friday night dates!\n",
      "Pred:  missing\n",
      "\n",
      "7e785e48c9 (positive, 0.5)\n",
      " good tip..... but then my boss would read .... exactly what im supposed to do and would know where I was with the project\n",
      "Answ:  good tip.\n",
      "Pred:  good\n",
      "\n",
      "23386e54b9 (positive, 0.25)\n",
      " thanks for your follow just do you own thing + join in with what interests you\n",
      "Answ:  thanks for your follow\n",
      "Pred:  thanks\n",
      "\n",
      "70762d960b (negative, 0.5)\n",
      " is sad that greg pritchard didnt make it through to the final of britains got talent coz he soooo deserved it\n",
      "Answ:  is sad\n",
      "Pred:  sad\n",
      "\n",
      "c6ab65bfbc (negative, 0.0)\n",
      " i really want a blackberry my sidekick is hella wack. night\n",
      "Answ:  sidekick\n",
      "Pred:  wack.\n",
      "\n",
      "533c72cf1f (negative, 0.0)\n",
      " lousy **** landlord. need to focus on kid`s packing but cant . nevermind sew sleeping bag\n",
      "Answ:  need to focus on kid`s packing but cant\n",
      "Pred:  lousy\n",
      "\n",
      "fb216c870d (positive, 0.2)\n",
      " Happy Birthday to my ****\n",
      "Answ:  Happy Birthday to my ****\n",
      "Pred:  Happy\n",
      "\n",
      "0d1925608e (positive, 0.16666666666666666)\n",
      " Ooo showing of your French skills!! lol Things good over here. Lovely weather, so should be outside How`s u?\n",
      "Answ:  Things good over here. Lovely weather,\n",
      "Pred:  good\n",
      "\n",
      "e1c1201fbf (positive, 0.14285714285714285)\n",
      " U no that little prob with ur twitter that happen @ that old pep resteraunt! mayb this will help u fix it\n",
      "Answ:  mayb this will help u fix it\n",
      "Pred:  help\n",
      "\n",
      "b7f7417fae (positive, 0.16666666666666666)\n",
      " great party alenka!! happy birthday chicky! <3\n",
      "Answ:  great party alenka!! happy birthday chicky!\n",
      "Pred:  great\n",
      "\n",
      "033d596615 (negative, 0.5)\n",
      " sorry guys, the WAVVES show was canceled, they missed their flight\n",
      "Answ:  sorry guys,\n",
      "Pred:  sorry\n",
      "\n",
      "77a91150bd (positive, 0.25)\n",
      " _luca LOL! I`m glad to see I`m not the only one out there!!!\n",
      "Answ:  I`m glad to see\n",
      "Pred:  glad\n",
      "\n",
      "a7995f1950 (negative, 0.4)\n",
      " no one told me the mutual admiration society was meeting this morning! LOL Hi boys!\n",
      "Answ:  no one told me the mutual admiration society was meeting\n",
      "Pred:  no one told me\n",
      "\n",
      "32f17aee22 (negative, 0.25)\n",
      " i`m still full from the buffet at palms. my stomach actually hurts. ugh gluttony bites.\n",
      "Answ:  my stomach actually hurts.\n",
      "Pred:  hurts.\n",
      "\n",
      "5383565acd (negative, 0.25)\n",
      " I`m a lil sad looks like nomore brooklyn 4 a while WTF\n",
      "Answ:  I`m a lil sad\n",
      "Pred:  sad\n",
      "\n",
      "b028a47082 (negative, 0.6666666666666666)\n",
      " soooo jelous of you right now\n",
      "Answ:  soooo jelous of you\n",
      "Pred:  soooo jelous of you right now\n",
      "\n",
      "57d8d754d3 (positive, 0.2)\n",
      " Finally a Black Disney princess.\n",
      "Answ:  Finally\n",
      "Pred:  Finally a Black Disney princess.\n",
      "\n",
      "37051dddd9 (negative, 0.25)\n",
      " awwwwww i wish her to be safe while shes gone n hugs to u must of been hard to say goodbye\n",
      "Answ:  hard to say goodbye\n",
      "Pred:  hard\n",
      "\n",
      "771f82173e (positive, 0.5)\n",
      " Thank you soooo much!!! Bella\n",
      "Answ:  Thank you\n",
      "Pred:  Thank you soooo much!!!\n",
      "[300]\n",
      "\n",
      "146503eb1e (negative, 0.3333333333333333)\n",
      " agh! freaking out about going to Wales already! >< not packed!!\n",
      "Answ:  freaking out\n",
      "Pred:  agh! freaking\n",
      "\n",
      "a068b95bd9 (negative, 0.2)\n",
      " Can you ask Ryan why he stopped following me on Twitter\n",
      "Answ:  stopped\n",
      "Pred:  stopped following me on Twitter\n",
      "\n",
      "3ade80fe74 (positive, 0.5)\n",
      " may gray, coldplay, and nice showers...work at 2\n",
      "Answ:  nice showers...\n",
      "Pred:  nice\n",
      "\n",
      "30c71ba325 (positive, 0.9444444444444444)\n",
      " . I want all the soldiers to come home so we don`t have to hear about anymore being killed.\n",
      "Answ:  . I want all the soldiers to come home so we don`t have to hear about anymore being killed.\n",
      "Pred:  I want all the soldiers to come home so we don`t have to hear about anymore being killed.\n",
      "\n",
      "3a1bdf5e7d (positive, 0.5)\n",
      " i love Paramore! welcome back\n",
      "Answ:  love\n",
      "Pred:  i love\n",
      "\n",
      "983d7b7aaa (negative, 0.16666666666666666)\n",
      " Sis...I dont think I will be up 4 2nite sadly Im in alot of pain 2day & had bad nite...can we go out anotha week soon?****\n",
      "Answ:  sadly\n",
      "Pred:  sadly Im in alot of pain\n",
      "\n",
      "ec1c0bed85 (negative, 0.5)\n",
      " miss you\n",
      "Answ:  miss\n",
      "Pred:  miss you\n",
      "\n",
      "b975892590 (positive, 0.07142857142857142)\n",
      " Happy Mothers Day to all the mom`s around Hope you have a wonderful day!\n",
      "Answ:  Happy Mothers Day to all the mom`s around Hope you have a wonderful day!\n",
      "Pred:  Happy\n",
      "\n",
      "fc96e25ebd (positive, 0.2)\n",
      " back to my interesting emails...\n",
      "Answ:  back to my interesting emails...\n",
      "Pred:  interesting\n",
      "\n",
      "973e2e7792 (positive, 0.75)\n",
      " oh wow THANKS Wayne\n",
      "Answ:  oh wow THANKS Wayne\n",
      "Pred:  oh wow THANKS\n",
      "\n",
      "522fd74625 (negative, 0.2857142857142857)\n",
      " Visiting family in hospital = not fun\n",
      "Answ:  Visiting family in hospital = not fun\n",
      "Pred:  not fun\n",
      "\n",
      "d4a79cd36a (negative, 0.3333333333333333)\n",
      " I lost my voice\n",
      "Answ:  lost\n",
      "Pred:  lost my voice\n",
      "\n",
      "1a0a876a35 (positive, 0.3333333333333333)\n",
      " I feel better today.\n",
      "Answ:  better\n",
      "Pred:  I feel better\n",
      "\n",
      "79dc6a41f9 (negative, 0.09090909090909091)\n",
      " My computer is being killed by a combo of mirrors edge and really poor win7 thermal management...75c gpu = one sad game\n",
      "Answ:  My computer is being killed by a combo of mirrors edge and really poor win7 thermal management...75c gpu = one sad game\n",
      "Pred:  sad game\n",
      "\n",
      "323e53905b (positive, 0.0)\n",
      " i bet they will be great bags! Can`t wait!\n",
      "Answ:  ! Can`t wait!\n",
      "Pred:  great\n",
      "\n",
      "79f7e6875e (positive, 0.14285714285714285)\n",
      " Already back from shopping and about to do a nice monday roast\n",
      "Answ:  about to do a nice monday roast\n",
      "Pred:  nice\n",
      "\n",
      "77f157bb4b (positive, 0.8181818181818182)\n",
      " Thanks a lot! You`re very kind! I just got back from a nice drive in the 500. Such a fun car to drive Have a nice day!\n",
      "Answ:  Thanks a lot! You`re very kind! I just got back from a nice drive in the 500. Such a fun car to drive Have a nice day\n",
      "Pred:  Thanks a lot! You`re very kind! I just got back from a nice drive in the 500. Such a fun\n",
      "\n",
      "ad6d957d50 (positive, 0.3333333333333333)\n",
      " Reese`s pieces ily\n",
      "Answ:  ily\n",
      "Pred:  Reese`s pieces ily\n",
      "\n",
      "7f420c3c39 (positive, 0.5)\n",
      " i wanna join the twit Club......\n",
      "Answ:  i wanna join\n",
      "Pred:  i wanna join the twit Club......\n",
      "\n",
      "4dafa796c5 (positive, 0.0)\n",
      " what about the dilfs? Oh wait, wrong month....HAPPY MOTHERS DAY\n",
      "Answ:  .HAPPY MOTHERS DAY\n",
      "Pred: HAPPY\n",
      "\n",
      "e60b496b41 (negative, 0.0)\n",
      " _xo wicked , what time you leaving? how come you cant stay the night\n",
      "Answ:  how come you cant stay\n",
      "Pred:  wicked\n",
      "\n",
      "a9e196f603 (negative, 0.2)\n",
      " http://twitpic.com/67uc7 - can you lend me one? I have a cold too\n",
      "Answ:  cold\n",
      "Pred:  I have a cold too\n",
      "\n",
      "cc4564d473 (positive, 0.05263157894736842)\n",
      " It`s not as bad if you don`t combine. FX are nice. I like Windows 7 1000x better than Vista so far. To me Vista is Win ME reborn\n",
      "Answ:  . FX are nice. I like Windows 7 1000x better than Vista so far. To me Vista is Win ME reborn\n",
      "Pred:  nice.\n",
      "\n",
      "ea95f16489 (positive, 0.0)\n",
      " have a glass of cold water and meditate a bit. <3\n",
      "Answ:  d meditate\n",
      "Pred:  <3\n",
      "\n",
      "e44c9e3d5a (negative, 0.5)\n",
      " I`m a new french girl in Twitter! And I speak English very bad\n",
      "Answ:  very bad\n",
      "Pred:  bad\n",
      "\n",
      "1cb2a0f0cf (positive, 0.5)\n",
      " _hawt Hmm.. Interesting choice.\n",
      "Answ:  Interesting choice.\n",
      "Pred:  Interesting\n",
      "\n",
      "3d3f95b048 (negative, 0.1)\n",
      " Wanna know a not fun way to wake up? Having a panic attack and not being able to breath for no **** reason, that **** sucked\n",
      "Answ:  **** sucked\n",
      "Pred:  not fun way to wake up? Having a panic attack and not being able to breath for no **** reason, that **** sucked\n",
      "\n",
      "9566981406 (positive, 0.5)\n",
      " thanks so much! we love fanmail talk to us anytime\n",
      "Answ:  thanks so much! we love fanmail talk to us anytime\n",
      "Pred:  thanks so much! we love\n",
      "\n",
      "85eff5452d (negative, 0.5714285714285714)\n",
      " People are just pisssing me offf. Ugh\n",
      "Answ:  pisssing me offf. Ugh\n",
      "Pred:  People are just pisssing me offf. Ugh\n",
      "\n",
      "df31ac9e8d (positive, 0.0)\n",
      " ugh, not sure i have the patience or remaining intelligence at this point in the day (week?) to refactor and rewrite this package of code\n",
      "Answ:  intelligence\n",
      "Pred:  ugh, not sure i have the patience\n",
      "\n",
      "48ba01d8cb (negative, 0.0)\n",
      " Still dealing with quite a bit of pain, will jump off here soon to lay down,very frustrating Thanks 4 asking\n",
      "Answ:  f pain\n",
      "Pred:  frustrating\n",
      "\n",
      "376271b337 (negative, 0.25)\n",
      " Now I feel sick.\n",
      "Answ:  Now I feel sick.\n",
      "Pred:  sick.\n",
      "\n",
      "2f64d9697c (positive, 0.45454545454545453)\n",
      " nice new profile picture! Glad to see some friends in there\n",
      "Answ:  nice new profile picture! Glad to see some friends in there\n",
      "Pred:  nice new profile picture! Glad\n",
      "\n",
      "1d753545cd (negative, 0.25)\n",
      " *hug* yep I hate that meself\n",
      "Answ:  I hate that meself\n",
      "Pred:  hate\n",
      "\n",
      "792063a20e (positive, 0.0)\n",
      " _Geronimo Thanks for sharing with your friends!\n",
      "Answ:  imo\n",
      "Pred:  Thanks\n",
      "\n",
      "99b69572a8 (negative, 0.5)\n",
      " im cold i still cant find my hoodie\n",
      "Answ:  cant find my hoodie\n",
      "Pred:  im cold i still cant find my hoodie\n",
      "\n",
      "6be7ac3209 (positive, 0.5)\n",
      " speakerphone with the bestie love that kid http://tinyurl.com/qxyc2n\n",
      "Answ:  bestie\n",
      "Pred:  bestie love\n",
      "\n",
      "a75db4a56f (positive, 0.25)\n",
      " awe thank you!! good morning to you aswell!!\n",
      "Answ:  thank you!\n",
      "Pred:  awe thank you!!\n",
      "\n",
      "ef2ad73798 (negative, 0.2)\n",
      " ok sweet! and whenever u want, I am stuck in bed all weekend\n",
      "Answ:  t, I am stuck in\n",
      "Pred:  stuck\n",
      "\n",
      "e851cd57b9 (positive, 0.5)\n",
      " That`s a great idea\n",
      "Answ:  That`s a great idea\n",
      "Pred:  great idea\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-c01db0b530e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m             start_logits, end_logits, _ = _model(ids,\n\u001b[1;32m     36\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 attention_mask=mask)\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/imgsrch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/senti_ext/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[1;32m     88\u001b[0m             hidden_states, _, hidden = self.bert(input_ids=input_ids,\n\u001b[1;32m     89\u001b[0m                                      \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                                      token_type_ids=token_type_ids)\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mhidden_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (-1, 192, 768*2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/imgsrch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/imgsrch/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_extended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         )\n\u001b[1;32m    792\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/imgsrch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/imgsrch/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             layer_outputs = layer_module(\n\u001b[0;32m--> 407\u001b[0;31m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             )\n\u001b[1;32m    409\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/imgsrch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/imgsrch/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     ):\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[0mself_attention_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add self attentions if we output attention weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/imgsrch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/imgsrch/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    312\u001b[0m     ):\n\u001b[1;32m    313\u001b[0m         self_outputs = self.self(\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         )\n\u001b[1;32m    316\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/imgsrch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/imgsrch/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "id_list = []\n",
    "answer = []\n",
    "sentiments = ['positive', 'negative', 'neutral']\n",
    "\n",
    "scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, d in enumerate(test_dataset):\n",
    "\n",
    "        if idx%100 == 0:\n",
    "            print('[{}]'.format(idx))\n",
    "\n",
    "        uniq_id =  test_data.textID.iloc[idx]\n",
    "        ids = d[\"ids\"]\n",
    "        token_type_ids = d[\"token_type_ids\"]\n",
    "        mask = d[\"mask\"]\n",
    "        sentiment = d[\"sentiment\"]\n",
    "        orig_selected = d[\"orig_selected\"]\n",
    "        orig_tweet = d[\"orig_tweet\"]\n",
    "        targets_start = d[\"targets_start\"]\n",
    "        targets_end = d[\"targets_end\"]\n",
    "        offsets = d[\"offsets\"].numpy()\n",
    "\n",
    "        ids = torch.unsqueeze(ids, dim=0).to(device, dtype=torch.long)\n",
    "        token_type_ids = torch.unsqueeze(token_type_ids, dim=0).to(device, dtype=torch.long)\n",
    "        mask = torch.unsqueeze(mask, dim=0).to(device, dtype=torch.long)\n",
    "\n",
    "        targets_start = targets_start.to(device, dtype=torch.long)\n",
    "        targets_end = targets_end.to(device, dtype=torch.long)\n",
    "\n",
    "        c = [] # sentiment classification\n",
    "        s = [] # start idx\n",
    "        e = [] # end idx\n",
    "        for _model in models:\n",
    "            start_logits, end_logits, _ = _model(ids,\n",
    "                token_type_ids=token_type_ids,\n",
    "                attention_mask=mask)\n",
    "            s.append(start_logits)\n",
    "            e.append(end_logits)\n",
    "\n",
    "        s_merged_logits = sum(s)/len(s)\n",
    "        e_merged_logits = sum(e)/len(e)\n",
    "\n",
    "        outputs_start = torch.softmax(s_merged_logits, dim=1).cpu().detach().numpy()\n",
    "        outputs_end = torch.softmax(e_merged_logits, dim=1).cpu().detach().numpy()\n",
    "\n",
    "        idx_start = np.argmax(outputs_start[0, :])\n",
    "        idx_end = np.argmax(outputs_end[0, :])\n",
    "\n",
    "        score, output_sentence = utils.calculate_jaccard_score(\n",
    "            original_tweet=orig_tweet,\n",
    "            target_string=orig_selected,\n",
    "            sentiment_val=sentiment,\n",
    "            idx_start=idx_start,\n",
    "            idx_end=idx_end,\n",
    "            offsets=offsets\n",
    "        )\n",
    "\n",
    "        scores.append(score)\n",
    "\n",
    "        if VERBOSE and sentiment != 'neutral' and score < 1.0:\n",
    "            print()\n",
    "            print(uniq_id, '({}, {})'.format(sentiment, score))\n",
    "            print(orig_tweet)\n",
    "            print('Answ:', orig_selected)\n",
    "            print('Pred:', output_sentence)\n",
    "\n",
    "        id_list.append(uniq_id)\n",
    "        answer.append(output_sentence)\n",
    "    print('=> avg score:', sum(scores)/len(scores))\n",
    "    print('------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
